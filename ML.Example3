import pandas as pd
     

import io
     

import pydotplus
     

from sklearn.impute import SimpleImputer#used for imputation(handling missing data)
     

from sklearn import tree
     

from sklearn import model_selection#when multiple models are there, to check the feature importance
     

Train=pd.read_csv('train.csv')
     

Train.shape
     
(891, 12)

Train.info()
     
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 891 entries, 0 to 890
Data columns (total 12 columns):
 #   Column       Non-Null Count  Dtype  
---  ------       --------------  -----  
 0   PassengerId  891 non-null    int64  
 1   Survived     891 non-null    int64  
 2   Pclass       891 non-null    int64  
 3   Name         891 non-null    object 
 4   Sex          891 non-null    object 
 5   Age          714 non-null    float64
 6   SibSp        891 non-null    int64  
 7   Parch        891 non-null    int64  
 8   Ticket       891 non-null    object 
 9   Fare         891 non-null    float64
 10  Cabin        204 non-null    object 
 11  Embarked     889 non-null    object 
dtypes: float64(2), int64(5), object(5)
memory usage: 83.7+ KB

Test=pd.read_csv('test.csv')
     

Test.shape
     
(418, 11)

Test.info()
     
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 418 entries, 0 to 417
Data columns (total 11 columns):
 #   Column       Non-Null Count  Dtype  
---  ------       --------------  -----  
 0   PassengerId  418 non-null    int64  
 1   Pclass       418 non-null    int64  
 2   Name         418 non-null    object 
 3   Sex          418 non-null    object 
 4   Age          332 non-null    float64
 5   SibSp        418 non-null    int64  
 6   Parch        418 non-null    int64  
 7   Ticket       418 non-null    object 
 8   Fare         417 non-null    float64
 9   Cabin        91 non-null     object 
 10  Embarked     418 non-null    object 
dtypes: float64(2), int64(4), object(5)
memory usage: 36.0+ KB

Test.Survived= None
     

Titanic=pd.concat([Train,Test])#used to combine two or more datasets.
     

Titanic.shape
     
(1309, 12)

Titanic.info()
Titanic.head()
     
<class 'pandas.core.frame.DataFrame'>
Int64Index: 1309 entries, 0 to 417
Data columns (total 12 columns):
 #   Column       Non-Null Count  Dtype  
---  ------       --------------  -----  
 0   PassengerId  1309 non-null   int64  
 1   Survived     891 non-null    float64
 2   Pclass       1309 non-null   int64  
 3   Name         1309 non-null   object 
 4   Sex          1309 non-null   object 
 5   Age          1046 non-null   float64
 6   SibSp        1309 non-null   int64  
 7   Parch        1309 non-null   int64  
 8   Ticket       1309 non-null   object 
 9   Fare         1308 non-null   float64
 10  Cabin        295 non-null    object 
 11  Embarked     1307 non-null   object 
dtypes: float64(3), int64(4), object(5)
memory usage: 132.9+ KB
PassengerId	Survived	Pclass	Name	Sex	Age	SibSp	Parch	Ticket	Fare	Cabin	Embarked
0	1	0.0	3	Braund, Mr. Owen Harris	male	22.0	1	0	A/5 21171	7.2500	NaN	S
1	2	1.0	1	Cumings, Mrs. John Bradley (Florence Briggs Th...	female	38.0	1	0	PC 17599	71.2833	C85	C
2	3	1.0	3	Heikkinen, Miss. Laina	female	26.0	0	0	STON/O2. 3101282	7.9250	NaN	S
3	4	1.0	1	Futrelle, Mrs. Jacques Heath (Lily May Peel)	female	35.0	1	0	113803	53.1000	C123	S
4	5	0.0	3	Allen, Mr. William Henry	male	35.0	0	0	373450	8.0500	NaN	S

def title(name):
  return name.split(',')[1].split('.')[0].strip()#it will extract the characters after , and before . in the title column
     

Titanic['Title']=Titanic['Name'].map(title)# we are creating a column named title in which the title from the name column is extracted and placed in this column
#map function is used as an alternative to for loop to make the work easier.
     
Alternate Code- for i=1 to 891 Titanic['Name']= name.split(',')[1].split('.')[0].strip()


mean=SimpleImputer()#by default parameter is mean.
     

mean.fit(Train[['Age','Fare']])
     
SimpleImputer()
In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook.
On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.

Titanic[['Age',"Fare"]]= mean.transform(Titanic[['Age','Fare']])
     

def conv(age):
  if(age >=0 and age <=1):
    return 'Infant'
  elif(age>1 and age<=12):
    return 'Child'
  elif(age>=13 and age<18):
    return 'Teenager'
  elif(age>=18 and age<30):
    return 'Young Adults'
  elif(age>=30 and age<40):
    return 'Middle Adults'
  elif(age>=40 and age<50):
    return 'Late Adults'
  elif(age>=50 and age<60):
    return 'Pre Old Age'
  else:
    return 'Old'

     

Titanic['Age_grp']=Titanic['Age'].map(conv)
     
Alternate Code- For i=1 to 1389 TItanic['Age_grp']= conv['Age'] i+=1


Titanic['Famsize']= Titanic['SibSp'] + Titanic['Parch'] +1
     

def conv_fam(size):
  if(size==1):
    return 'Single'
  elif(size>2 and size <=4):
    return 'Small'
  elif(size>4 and size <=6):
    return 'Medium'
  else:
    return 'Large'
     

Titanic['Fam_cat']=Titanic['Famsize'].map(conv_fam)
     

def conv_fares(price):
  if(price>=0 and price<25):
    return 'Standard'
  elif(price>=25 and price<50):
    return 'Premium'
  elif(price>=50 and price<100):
    return 'Ultra'
  elif(price>=100 and price<200):
    return 'Max'
  else:
    return 'OP'
     

Titanic['Fare_cat']=Titanic['Fare'].map(conv_fares)
     

titanic=pd.get_dummies(Titanic,columns=['Sex','Pclass','Embarked','Age_grp','Fam_cat','Fare_cat','Title'])
     

titanic.shape
     
(1309, 53)

titanic.info()
     
<class 'pandas.core.frame.DataFrame'>
Int64Index: 1309 entries, 0 to 417
Data columns (total 53 columns):
 #   Column                 Non-Null Count  Dtype  
---  ------                 --------------  -----  
 0   PassengerId            1309 non-null   int64  
 1   Survived               891 non-null    float64
 2   Name                   1309 non-null   object 
 3   Age                    1309 non-null   float64
 4   SibSp                  1309 non-null   int64  
 5   Parch                  1309 non-null   int64  
 6   Ticket                 1309 non-null   object 
 7   Fare                   1309 non-null   float64
 8   Cabin                  295 non-null    object 
 9   Famsize                1309 non-null   int64  
 10  Sex_female             1309 non-null   uint8  
 11  Sex_male               1309 non-null   uint8  
 12  Pclass_1               1309 non-null   uint8  
 13  Pclass_2               1309 non-null   uint8  
 14  Pclass_3               1309 non-null   uint8  
 15  Embarked_C             1309 non-null   uint8  
 16  Embarked_Q             1309 non-null   uint8  
 17  Embarked_S             1309 non-null   uint8  
 18  Age_grp_Child          1309 non-null   uint8  
 19  Age_grp_Infant         1309 non-null   uint8  
 20  Age_grp_Late Adults    1309 non-null   uint8  
 21  Age_grp_Middle Adults  1309 non-null   uint8  
 22  Age_grp_Old            1309 non-null   uint8  
 23  Age_grp_Pre Old Age    1309 non-null   uint8  
 24  Age_grp_Teenager       1309 non-null   uint8  
 25  Age_grp_Young Adults   1309 non-null   uint8  
 26  Fam_cat_Large          1309 non-null   uint8  
 27  Fam_cat_Medium         1309 non-null   uint8  
 28  Fam_cat_Single         1309 non-null   uint8  
 29  Fam_cat_Small          1309 non-null   uint8  
 30  Fare_cat_Max           1309 non-null   uint8  
 31  Fare_cat_OP            1309 non-null   uint8  
 32  Fare_cat_Premium       1309 non-null   uint8  
 33  Fare_cat_Standard      1309 non-null   uint8  
 34  Fare_cat_Ultra         1309 non-null   uint8  
 35  Title_Capt             1309 non-null   uint8  
 36  Title_Col              1309 non-null   uint8  
 37  Title_Don              1309 non-null   uint8  
 38  Title_Dona             1309 non-null   uint8  
 39  Title_Dr               1309 non-null   uint8  
 40  Title_Jonkheer         1309 non-null   uint8  
 41  Title_Lady             1309 non-null   uint8  
 42  Title_Major            1309 non-null   uint8  
 43  Title_Master           1309 non-null   uint8  
 44  Title_Miss             1309 non-null   uint8  
 45  Title_Mlle             1309 non-null   uint8  
 46  Title_Mme              1309 non-null   uint8  
 47  Title_Mr               1309 non-null   uint8  
 48  Title_Mrs              1309 non-null   uint8  
 49  Title_Ms               1309 non-null   uint8  
 50  Title_Rev              1309 non-null   uint8  
 51  Title_Sir              1309 non-null   uint8  
 52  Title_the Countess     1309 non-null   uint8  
dtypes: float64(3), int64(4), object(3), uint8(43)
memory usage: 167.5+ KB

titanic.head()
     
PassengerId	Survived	Name	Age	SibSp	Parch	Ticket	Fare	Cabin	Famsize	...	Title_Master	Title_Miss	Title_Mlle	Title_Mme	Title_Mr	Title_Mrs	Title_Ms	Title_Rev	Title_Sir	Title_the Countess
0	1	0.0	Braund, Mr. Owen Harris	22.0	1	0	A/5 21171	7.2500	NaN	2	...	0	0	0	0	1	0	0	0	0	0
1	2	1.0	Cumings, Mrs. John Bradley (Florence Briggs Th...	38.0	1	0	PC 17599	71.2833	C85	2	...	0	0	0	0	0	1	0	0	0	0
2	3	1.0	Heikkinen, Miss. Laina	26.0	0	0	STON/O2. 3101282	7.9250	NaN	1	...	0	1	0	0	0	0	0	0	0	0
3	4	1.0	Futrelle, Mrs. Jacques Heath (Lily May Peel)	35.0	1	0	113803	53.1000	C123	2	...	0	0	0	0	0	1	0	0	0	0
4	5	0.0	Allen, Mr. William Henry	35.0	0	0	373450	8.0500	NaN	1	...	0	0	0	0	1	0	0	0	0	0
5 rows Ã— 53 columns


training = titanic.drop(['PassengerId' , 'Name' , 'Age' , 'Ticket' , 'Cabin' , 'SibSp' , 'Parch','Survived'],axis=1,inplace=False)
     

training.shape
     
(1309, 45)

training.info()
     
<class 'pandas.core.frame.DataFrame'>
Int64Index: 1309 entries, 0 to 417
Data columns (total 45 columns):
 #   Column                 Non-Null Count  Dtype  
---  ------                 --------------  -----  
 0   Fare                   1309 non-null   float64
 1   Famsize                1309 non-null   int64  
 2   Sex_female             1309 non-null   uint8  
 3   Sex_male               1309 non-null   uint8  
 4   Pclass_1               1309 non-null   uint8  
 5   Pclass_2               1309 non-null   uint8  
 6   Pclass_3               1309 non-null   uint8  
 7   Embarked_C             1309 non-null   uint8  
 8   Embarked_Q             1309 non-null   uint8  
 9   Embarked_S             1309 non-null   uint8  
 10  Age_grp_Child          1309 non-null   uint8  
 11  Age_grp_Infant         1309 non-null   uint8  
 12  Age_grp_Late Adults    1309 non-null   uint8  
 13  Age_grp_Middle Adults  1309 non-null   uint8  
 14  Age_grp_Old            1309 non-null   uint8  
 15  Age_grp_Pre Old Age    1309 non-null   uint8  
 16  Age_grp_Teenager       1309 non-null   uint8  
 17  Age_grp_Young Adults   1309 non-null   uint8  
 18  Fam_cat_Large          1309 non-null   uint8  
 19  Fam_cat_Medium         1309 non-null   uint8  
 20  Fam_cat_Single         1309 non-null   uint8  
 21  Fam_cat_Small          1309 non-null   uint8  
 22  Fare_cat_Max           1309 non-null   uint8  
 23  Fare_cat_OP            1309 non-null   uint8  
 24  Fare_cat_Premium       1309 non-null   uint8  
 25  Fare_cat_Standard      1309 non-null   uint8  
 26  Fare_cat_Ultra         1309 non-null   uint8  
 27  Title_Capt             1309 non-null   uint8  
 28  Title_Col              1309 non-null   uint8  
 29  Title_Don              1309 non-null   uint8  
 30  Title_Dona             1309 non-null   uint8  
 31  Title_Dr               1309 non-null   uint8  
 32  Title_Jonkheer         1309 non-null   uint8  
 33  Title_Lady             1309 non-null   uint8  
 34  Title_Major            1309 non-null   uint8  
 35  Title_Master           1309 non-null   uint8  
 36  Title_Miss             1309 non-null   uint8  
 37  Title_Mlle             1309 non-null   uint8  
 38  Title_Mme              1309 non-null   uint8  
 39  Title_Mr               1309 non-null   uint8  
 40  Title_Mrs              1309 non-null   uint8  
 41  Title_Ms               1309 non-null   uint8  
 42  Title_Rev              1309 non-null   uint8  
 43  Title_Sir              1309 non-null   uint8  
 44  Title_the Countess     1309 non-null   uint8  
dtypes: float64(1), int64(1), uint8(43)
memory usage: 85.6 KB

x_train=training[0:891]
     

x_train.shape
     
(891, 45)

y_train=Train['Survived']
     

dt=tree.DecisionTreeClassifier(max_depth=5)
dt.fit(x_train,y_train)
     
DecisionTreeClassifier(max_depth=5)
In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook.
On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.

dt1= {'min_samples_split':[2,3,6,7,8], 'criterion':['gini','entropy']}
     

#dt_grid = {'max_depth':list(range(10,30)), 'min_samples_split':list(range(2,8)), 'criterion':['gini','entropy']}
     
the decision tree goes to the absolute depth but not all the times its good thats why we are limiting its depth using these functions- max depth is used to cut the tree and min sample is used to define at which value the tree should stop.


dt_grid=model_selection.GridSearchCV(dt,dt1,cv=9)#Evolution of tree
dt_grid.fit(x_train,y_train)#building of tree
dt_grid.cv_results_
     
{'mean_fit_time': array([0.00456802, 0.00416345, 0.00396   , 0.00450095, 0.00408567,
        0.00403923, 0.00437495, 0.00414952, 0.00449475, 0.00427259]),
 'std_fit_time': array([1.64081157e-03, 5.17696990e-04, 1.13657088e-04, 1.58441083e-03,
        5.63941396e-04, 7.72952541e-05, 8.95153466e-04, 2.72663981e-04,
        9.15640703e-04, 4.42884159e-04]),
 'mean_score_time': array([0.00214836, 0.00213782, 0.00206137, 0.0020224 , 0.00195363,
        0.00201352, 0.00213183, 0.00207477, 0.00225157, 0.00208619]),
 'std_score_time': array([2.22019903e-04, 2.44251401e-04, 1.11294810e-04, 1.32003875e-04,
        3.36145667e-05, 5.08899417e-05, 2.63978506e-04, 1.27131727e-04,
        4.83208604e-04, 6.25188741e-05]),
 'param_criterion': masked_array(data=['gini', 'gini', 'gini', 'gini', 'gini', 'entropy',
                    'entropy', 'entropy', 'entropy', 'entropy'],
              mask=[False, False, False, False, False, False, False, False,
                    False, False],
        fill_value='?',
             dtype=object),
 'param_min_samples_split': masked_array(data=[2, 3, 6, 7, 8, 2, 3, 6, 7, 8],
              mask=[False, False, False, False, False, False, False, False,
                    False, False],
        fill_value='?',
             dtype=object),
 'params': [{'criterion': 'gini', 'min_samples_split': 2},
  {'criterion': 'gini', 'min_samples_split': 3},
  {'criterion': 'gini', 'min_samples_split': 6},
  {'criterion': 'gini', 'min_samples_split': 7},
  {'criterion': 'gini', 'min_samples_split': 8},
  {'criterion': 'entropy', 'min_samples_split': 2},
  {'criterion': 'entropy', 'min_samples_split': 3},
  {'criterion': 'entropy', 'min_samples_split': 6},
  {'criterion': 'entropy', 'min_samples_split': 7},
  {'criterion': 'entropy', 'min_samples_split': 8}],
 'split0_test_score': array([0.77777778, 0.77777778, 0.76767677, 0.76767677, 0.77777778,
        0.85858586, 0.84848485, 0.84848485, 0.84848485, 0.84848485]),
 'split1_test_score': array([0.84848485, 0.84848485, 0.84848485, 0.82828283, 0.82828283,
        0.82828283, 0.83838384, 0.83838384, 0.84848485, 0.83838384]),
 'split2_test_score': array([0.74747475, 0.74747475, 0.75757576, 0.75757576, 0.74747475,
        0.75757576, 0.75757576, 0.75757576, 0.75757576, 0.75757576]),
 'split3_test_score': array([0.91919192, 0.91919192, 0.92929293, 0.92929293, 0.91919192,
        0.90909091, 0.90909091, 0.90909091, 0.91919192, 0.90909091]),
 'split4_test_score': array([0.81818182, 0.82828283, 0.81818182, 0.81818182, 0.81818182,
        0.81818182, 0.81818182, 0.81818182, 0.81818182, 0.81818182]),
 'split5_test_score': array([0.81818182, 0.81818182, 0.81818182, 0.82828283, 0.82828283,
        0.82828283, 0.82828283, 0.82828283, 0.82828283, 0.82828283]),
 'split6_test_score': array([0.80808081, 0.7979798 , 0.7979798 , 0.7979798 , 0.7979798 ,
        0.7979798 , 0.7979798 , 0.7979798 , 0.7979798 , 0.7979798 ]),
 'split7_test_score': array([0.84848485, 0.84848485, 0.84848485, 0.85858586, 0.85858586,
        0.85858586, 0.85858586, 0.85858586, 0.85858586, 0.85858586]),
 'split8_test_score': array([0.81818182, 0.81818182, 0.81818182, 0.81818182, 0.81818182,
        0.83838384, 0.83838384, 0.83838384, 0.83838384, 0.83838384]),
 'mean_test_score': array([0.82267116, 0.82267116, 0.82267116, 0.82267116, 0.82154882,
        0.83277217, 0.83277217, 0.83277217, 0.83501684, 0.83277217]),
 'std_test_score': array([0.04545108, 0.04594723, 0.04788042, 0.04788042, 0.0459198 ,
        0.03987053, 0.03929774, 0.03929774, 0.04178341, 0.03929774]),
 'rank_test_score': array([ 6,  6,  9,  6, 10,  2,  2,  2,  1,  2], dtype=int32)}
cv means we are breaking the train data into n small validation data for testing cv stands for Cross Validation grid search cv is used to search for the best model in the 30 outcome models which we will be getting


objStringIO=io.StringIO()
tree.export_graphviz(dt,out_file=objStringIO,feature_names=x_train.columns)
     

file1=pydotplus.graph_from_dot_data(objStringIO.getvalue())
file1.write_pdf("DecisionTree2.pdf")
     
True

dt1.best_score_
#dt1.best_params_
     
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-150-571b765b1b04> in <cell line: 1>()
----> 1 dt1.best_score_
      2 #dt1.best_params_

AttributeError: 'dict' object has no attribute 'best_score_'

f=pd.DataFrame({'Feature':x_train.columns, 'importance': dt1.best_estimator_.feature_importances_})
f
     
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-140-ddf5eb133dfd> in <cell line: 1>()
----> 1 f=pd.DataFrame({'Feature':x_train.columns, 'importance': dt1.best_estimator_.feature_importances_})
      2 f

AttributeError: 'dict' object has no attribute 'best_estimator_'

x_test=training[Train.shape[0]:]
     

x_test.shape
     
(418, 45)

Test['Survived']=param_grid.predict(x_test)
     

Test.to_csv('Attempt5.7.csv',columns=['PassengerId','Survived'],index=False)
     

param_grid.best_score_#after changing cv to 15
     
0.808210922787194

param_grid.best_score_#after changing the cv cv=5
     
0.8125415855878476

param_grid.best_score_#removing sample splits(15,16,17)(2,3)
     
0.7957351290684624

param_grid.best_score_#after changing max depth (15,16,17),(2,3,6,7,8)
     
0.8170594837261503

param_grid.best_score_#first attempt  (10,11,12)(2,3,6,7,8)
     
0.8114478114478115
